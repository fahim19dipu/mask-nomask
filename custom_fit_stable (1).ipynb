{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966457b6",
   "metadata": {},
   "source": [
    "# Nybsys Recruitment Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87921c2",
   "metadata": {},
   "source": [
    "### Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e615421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.6/bin\")\n",
    "\n",
    "from functools import partial\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8cf8e",
   "metadata": {},
   "source": [
    "### Intialzing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18bc3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#AUTOTUNE = 15\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0300b",
   "metadata": {},
   "source": [
    "### Plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8d5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the confussion matrix of trained model\n",
    "def plot_cm(labels, predictions):\n",
    "  cm = tf.math.confusion_matrix(labels, predictions)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix')\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Unmasked image Detected (True Negatives): ', cm[0][0])\n",
    "  print('Unmasked image Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Masked image Missed (False Negatives): ', cm[1][0])\n",
    "  print('Masked image Detected (True Positives): ', cm[1][1])\n",
    "  print('Total masked image Transactions: ', np.sum(cm[1]))\n",
    "\n",
    "### Plot various losses of the model with respect to epochs\n",
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "\n",
    "### Plot various metrices of the model with respect to epochs\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend();\n",
    "    \n",
    "### view images from a batch\n",
    "def view_image(ds):\n",
    "    image, label = next(iter(ds)) # extract 1 batch from the dataset\n",
    "    image = image.numpy()\n",
    "    label = label.numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(22, 22))\n",
    "    for i in range(20):\n",
    "        ax = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(image[i])\n",
    "        ax.set_title(f\"Label: {label[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cbe2c",
   "metadata": {},
   "source": [
    "### Parsing methods for dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c6d74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### reset the shape of the instaces of the dataset \n",
    "def set_shapes(img, label, img_shape=(120,120,3)):\n",
    "    img.set_shape(img_shape)\n",
    "    return img, label\n",
    "### read , decode and normalize the images\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image_decoded = tf.image.resize(image_decoded, [120, 120])\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "def _parse_function_2(filename):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image_decoded = tf.image.resize(image_decoded, [120, 120])\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    \n",
    "    return image.numpy()\n",
    "### make dataset with given list of filenames and respective lebels\n",
    "def make_ds(features, labels):\n",
    "    labels = tf.one_hot(labels,2)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
    "    ds = ds.map(_parse_function)\n",
    "    ds = ds.shuffle(BUFFER_SIZE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f83796",
   "metadata": {},
   "source": [
    "### Augmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0540c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply augmentation function on a dataset\n",
    "def process_data(image, label, img_size):\n",
    "    aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "    return aug_img, label\n",
    "\n",
    "def aug_fn(image, img_size):\n",
    "    data = {\"image\":image}\n",
    "    transforms = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    #A.RandomBrightnessContrast(p=0.2),\n",
    "            ])\n",
    "    aug_data = transforms(**data)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    return aug_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e723f6",
   "metadata": {},
   "source": [
    "### Validation and Test Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54b4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_dataloader():\n",
    "    \n",
    "    val_files_mask = [f for f in glob.glob(\"F:/nybsys project/mask_non_mask/mask/val/*/*\")]\n",
    "    val_label = [1]*len(val_files_mask)\n",
    "    \n",
    "    val_files_nonmask = [f for f in glob.glob(\"F:/nybsys project/mask_non_mask/nonmask/val/*/*\")]\n",
    "    val_label = val_label + [0]*len(val_files_nonmask)\n",
    "    \n",
    "    val_files = val_files_mask+ val_files_nonmask\n",
    "    #############################################################################################\n",
    "    val_label = tf.one_hot(val_label,2)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_files,val_label ))\n",
    "    \n",
    "    val_dataset = val_dataset.map(_parse_function)\n",
    "    val_dataset=  val_dataset.map(set_shapes, num_parallel_calls=AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    #############################################################################################\n",
    "    print(val_dataset)\n",
    "    print(tf.data.experimental.cardinality(val_dataset).numpy())\n",
    "    \n",
    "    return val_dataset\n",
    "\n",
    "def test_dataloader():\n",
    "\n",
    "    test_files_mask = [f for f in glob.glob(\"F:/nybsys project/mask_non_mask/mask/test/*/*\")]\n",
    "    test_label = [1]*len(test_files_mask)\n",
    "    \n",
    "    test_files_nonmask = [f for f in glob.glob(\"F:/nybsys project/mask_non_mask/nonmask/test/*/*\")]\n",
    "    test_label = test_label + [0]*len(test_files_nonmask)\n",
    "    \n",
    "    test_files = test_files_mask+ test_files_nonmask\n",
    "    #############################################################################################\n",
    "    test_label = tf.one_hot(test_label,2)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_files,test_label )) \n",
    "    \n",
    "    test_dataset = test_dataset.map(_parse_function)\n",
    "    test_dataset=  test_dataset.map(set_shapes, num_parallel_calls=AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    #############################################################################################\n",
    "    print(test_dataset)\n",
    "    print(tf.data.experimental.cardinality(test_dataset).numpy())\n",
    "    \n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86cbcb",
   "metadata": {},
   "source": [
    "### Train Dataloader with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d90389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataloader():\n",
    "    \n",
    "    train_files_mask = [f for f in glob.glob('F:/nybsys project/mask_non_mask/mask/train/*/*')]\n",
    "    train_label_mask = [1]*len(train_files_mask)\n",
    "\n",
    "    train_files_nonmask = [f for f in glob.glob('F:/nybsys project/mask_non_mask/nonmask/train/*/*' )]\n",
    "    train_label_nonmask = [0]*len(train_files_nonmask)\n",
    "\n",
    "    pos_ds = make_ds(train_files_mask, train_label_mask)\n",
    "    ###################################################################################\n",
    "    \"\"\"Applying augmentation\"\"\"\n",
    "    aug_1_ds = pos_ds.map(partial(process_data, img_size=120),\n",
    "                      num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    pos_ds = pos_ds.concatenate(aug_1_ds)\n",
    "    \n",
    "    aug_2_ds = pos_ds.map(partial(process_data, img_size=120),\n",
    "                      num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    pos_ds = pos_ds.concatenate(aug_2_ds)\n",
    "    \n",
    "    aug_3_ds = pos_ds.map(partial(process_data, img_size=120),\n",
    "                      num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    pos_ds = pos_ds.concatenate(aug_3_ds)\n",
    "    \n",
    "    aug_4_ds = pos_ds.map(partial(process_data, img_size=120),\n",
    "                      num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    pos_ds = pos_ds.concatenate(aug_4_ds)\n",
    "    \n",
    "    aug_5_ds = pos_ds.map(partial(process_data, img_size=120),\n",
    "                      num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    pos_ds = pos_ds.concatenate(aug_5_ds)\n",
    "    \n",
    "    aug_6_ds = pos_ds.map(partial(process_data, img_size=120),\n",
    "                      num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    pos_ds = pos_ds.concatenate(aug_6_ds)\n",
    "    \n",
    "    print(tf.data.experimental.cardinality(pos_ds).numpy())\n",
    "    ###################################################################################\n",
    "    neg_ds = make_ds(train_files_nonmask, train_label_nonmask)\n",
    "    neg_ds = neg_ds.map(partial(process_data, img_size=120),\n",
    "                      num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    print(tf.data.experimental.cardinality(neg_ds).numpy())\n",
    "    \n",
    "    resampled_ds = tf.data.Dataset.sample_from_datasets([pos_ds, neg_ds], weights=[0.05,0.95])\n",
    "    \n",
    "    resampled_ds = resampled_ds.batch(BATCH_SIZE).shuffle(BUFFER_SIZE).prefetch(AUTOTUNE)\n",
    "    print(resampled_ds)\n",
    "\n",
    "    for features, label in resampled_ds.take(1):\n",
    "        print(label.numpy().mean())\n",
    "\n",
    "\n",
    "    return resampled_ds\n",
    "#training_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cfeaea",
   "metadata": {},
   "source": [
    "### Making Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f449966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape,metrics=METRICS):\n",
    "    model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(2, activation='sigmoid')])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "                  loss=[tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                        tf.keras.losses.KLDivergence()],metrics=metrics)\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b0f82",
   "metadata": {},
   "source": [
    "### Calling functions to create datasets and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc4f861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16064\n",
      "14329\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n",
      "0.5\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 120, 120, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n",
      "80\n",
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 120, 120, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "train_dataset = training_dataloader()\n",
    "val_dataset = val_dataloader()\n",
    "test_dataset= test_dataloader()\n",
    "model= make_model((120,120,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d1f62",
   "metadata": {},
   "source": [
    "### Custom training and validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1bd2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "@tf.function\n",
    "def model_train(features, labels):\n",
    "    # Define the GradientTape context\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get the probabilities\n",
    "        predictions = model(features)\n",
    "        # Calculate the loss\n",
    "        loss1 = loss_func_1(labels, predictions)\n",
    "        loss2 = loss_func_2(labels, predictions)\n",
    "        loss = tf.add(loss1,loss2)\n",
    "        \n",
    "    # Get the gradients\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # Update the weights\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Update the loss and accuracy\n",
    "    train_loss(loss)\n",
    "    train_acc(labels, predictions)\n",
    "\n",
    "# Validating the model\n",
    "@tf.function\n",
    "def model_validate(features, labels):\n",
    "    predictions = model(features)\n",
    "    v_loss = loss_func_1(labels, predictions)\n",
    "\n",
    "    valid_loss(v_loss)\n",
    "    valid_acc(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cecc67d",
   "metadata": {},
   "source": [
    "### Training with augmented train datatset while evaluated with given validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba537cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n",
      "Epoch 1, loss: 7.540, acc: 0.730, val_loss: 0.517, val_acc: 0.729\n",
      "Epoch 2, loss: 0.235, acc: 0.935, val_loss: 0.221, val_acc: 0.942\n"
     ]
    }
   ],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "valid_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "\n",
    "# Specify the performance metric\n",
    "train_acc = tf.keras.metrics.BinaryAccuracy(name=\"train_acc\")\n",
    "valid_acc = tf.keras.metrics.BinaryAccuracy(name=\"valid_acc\")\n",
    "loss_func_1 = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_func_2 = tf.keras.losses.KLDivergence()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "print(\"Training Started\")\n",
    "# Train the model for 2 epochs\n",
    "for epoch in range(2):\n",
    "    # Run the model through train and test sets respectively\n",
    "    for (features, labels) in train_dataset:\n",
    "        model_train(features, labels)\n",
    "\n",
    "    for val_features, val_labels in val_dataset:\n",
    "        model_validate(val_features, val_labels)\n",
    "        \n",
    "    # Grab the results\n",
    "    (loss, acc) = train_loss.result(), train_acc.result()\n",
    "    (val_loss, val_acc) = valid_loss.result(), valid_acc.result()\n",
    "    \n",
    "    # Clear the current state of the metrics\n",
    "    train_loss.reset_states(), train_acc.reset_states()\n",
    "    valid_loss.reset_states(), valid_acc.reset_states()\n",
    "    \n",
    "    # Local logging\n",
    "    template = \"Epoch {}, loss: {:.3f}, acc: {:.3f}, val_loss: {:.3f}, val_acc: {:.3f}\"\n",
    "    print (template.format(epoch+1,\n",
    "                         loss,\n",
    "                         acc,\n",
    "                         val_loss,\n",
    "                         val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc5446",
   "metadata": {},
   "source": [
    "### Evalaute trained model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3b0aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 22s 188ms/step - loss: 0.1608 - tp: 5088.0000 - fp: 365.0000 - tn: 4887.0000 - fn: 164.0000 - accuracy: 0.9496 - precision: 0.9331 - recall: 0.9688 - auc: 0.9865 - prc: 0.9849\n",
      "Test Confusion Matrix\n",
      "tf.Tensor(\n",
      "[[4901  266]\n",
      " [  76    9]], shape=(2, 2), dtype=int32)\n",
      "Unmasked image Detected (True Negatives):  tf.Tensor(4901, shape=(), dtype=int32)\n",
      "Unmasked image Incorrectly Detected (False Positives):  tf.Tensor(266, shape=(), dtype=int32)\n",
      "Masked image Missed (False Negatives):  tf.Tensor(76, shape=(), dtype=int32)\n",
      "Masked image Detected (True Positives):  tf.Tensor(9, shape=(), dtype=int32)\n",
      "Total masked image Transactions:  85\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      5167\n",
      "           1       0.03      0.11      0.05        85\n",
      "\n",
      "    accuracy                           0.93      5252\n",
      "   macro avg       0.51      0.53      0.51      5252\n",
      "weighted avg       0.97      0.93      0.95      5252\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)\n",
    "\n",
    "y_pred = model.predict(test_dataset)\n",
    "y_pred = tf.argmax(y_pred, axis = 1)\n",
    "\n",
    "print('Test Confusion Matrix')\n",
    "y = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "y = tf.argmax(y, axis = 1)\n",
    "cm =tf.math.confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "plot_cm(y, y_pred)\n",
    "import  sklearn\n",
    "print('Test Classification Report')\n",
    "print(sklearn.metrics.classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "812966cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name =  \"model_acc_\"+str(cm[1][1])\n",
    "model_json = model.to_json()\n",
    "dire = \"F:/nybsys project/\"+file_name+\".json\"\n",
    "dire2 = \"F:/nybsys project/\"+file_name+\".h5\"\n",
    "with open(dire,\"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "model.save(dire2) \n",
    "#model.save('F:/nybsys project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c08203bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 2.5934769e-05]]\n",
      "tf.Tensor([0], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"F:/nybsys project/corr/1648442725413.jpeg\"\n",
    "image = _parse_function_2(image_path)\n",
    "#print(image)\n",
    "image = image.reshape(1,120,120,3)\n",
    "y_pred = model.predict(image)\n",
    "print(y_pred)\n",
    "y_pred = tf.argmax(y_pred, axis = 1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53527d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4bf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
